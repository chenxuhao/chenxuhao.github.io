<html lang="en">
<head>
  <meta charset="utf-8">

  <title>GPU Computing</title>
  <link href="https://fonts.googleapis.com/css?family=Lato|Open+Sans" rel="stylesheet">
<style>
body {
	font-family: 'Open Sans', sans-serif;
}
div#content {
	padding:			50px;
	margin-left:		auto;
	margin-right:		auto;
	width:	    		800px;
	min-height:			420px;
	background-color:	#ffffff;
	position:			relative;
}
h1 {
	color:			#80bd01;
	font-family: 'Lato', sans-serif;
}
h2 {
	color:			#80bd01;
	font-family: 'Lato', sans-serif;
}
h3 {
	color:			#80bd01;
	font-family: 'Lato', sans-serif;
	margin-left:  20px;
}
h4 {
	margin-left:  20px;
}
a {
	text-decoration: none;
	color: #000;
	border-bottom: 1px solid #d4d4d4;
}
a:hover {
	color: 			#fb6300;
}
table {
	margin: 20px;
	margin-left: 40px;
	border:#ccc 1px solid;
}
table tr {
	text-align: center;
	padding-left:20px;
}
table td {
	padding: 8px 24px;
	border: 1px solid #e0e0e0;
}
p {
	margin-left: 40px;
}
</style>

</head>

<body>
  
<div id="content">

<h2 style="text-align:center"> TBD </h2>
<h1 style="text-align:center"> GPU Computing </h1>

<center>
<h4> Location, Time <br/>
Instructor: <a href="https://chenxuhao.github.io/">Xuhao Chen</a> <br/>
Office Hours: Time, Location </h4>
</center>

<h2> Course Description </h2>

<p>This course is an introduction to parallel computing using graphics processing units (GPUs). We will be focussing on CUDA programming, but the concepts taught will apply to other GPU frameworks as well. The course will start by covering CUDA syntax extensions and the CUDA runtime API, then move on to more advanced topics such as bandwidth optimization, memory access performance, and floating point considerations. We will learn about common parallel computing patterns such as scans and reductions, and study use cases for GPU acceleration such as matrix multiplication and convolution.</p>

<h3> Prerequisites </h3>

<p>As CUDA is an extension of the C language, students taking this course should be familiar with C programming.</p>

<p>Prior knowledge of computer architecture concepts such as data locality will be useful but not required.</p>

<h3> Grading </h3>

<p>Grades for this course will be based on a series of 3-5 programming assignments designed to allow students to apply GPU programming skills taught in the lectures.</p>

<h3> Textbook (Optional) </h3>

<p> <strong>Programming Massively Parallel Processors, Third Edition: A Hands-on Approach</strong> <br/> David B. Kirk and Wen-mei W. Hwu. </p> 

<p> The Second Edition is online available <a href="https://safari.ethz.ch/architecture/fall2019/lib/exe/fetch.php?media=2013_programming_massively_parallel_processors_a_hands-on_approach_2nd.pdf">here</a> </p>

<h3> Computing Resources </h3>

<p> For the programming assignments, students will need access to a computer with a <a href="https://developer.nvidia.com/cuda-gpus">CUDA-compatible GPU</a>. 
I can help arrange access to a remote CUDA-capable machine for students without local access. </p>

<p> <a href="https://developer.nvidia.com/teaching-kits">The NVIDIA Deep Learning Institute (DLI) Teaching Kit Program</a> </p>

<p> <a href="http://webgpu.com/">WebGPU.com A System for Online GPU Development</a> </p>

<p> <a href="http://impact.crhc.illinois.edu/shared/PR/SC16_PMPP_Educators_Sessions_FINAL.pdf">Teach GPU Accelerating Computing: Hands-on with NVIDIA Teaching Kit for Educators</a> </p>

<h2> Schedule and Slides (subject to change)</h2>

<table cellspacing="0">
<tr> <td> 3 / 27 </td> <td> <a href="Lecture01.pdf">Course Introduction</a> </td> <td> </td> </tr>
<tr> <td> 3 / 29 </td> <td> <a href="Lecture02.pdf">Intro to CUDA C</a> </td> <td> <a href="assignments/axpy.tar.gz">axpy</a> </td> </tr>
<tr> <td> 4 / 03 </td> <td> <a href="Lecture03.pdf">CUDA parallelism model</a> </td> <td> </td> </tr>
<tr> <td> 4 / 05 </td> <td> <a href="Lecture04.pdf">Memory and data locality</a> <br/>
<a href="Lecture05.pdf">Thread execution / computational efficiency</a> </td> <td> <a href="assignments/TiledMatrixMultiplication.tar.gz">TiledMatrixMultiplication</a> </td> </tr>
<tr> <td> 4 / 10 </td> <td> <a href="Lecture06.pdf">Memory performance</a> <br/> <a href="Lecture07.pdf">Stencil pattern</a> </td> <td> </td> </tr>
<tr> <td> 4 / 12 </td> <td> <a href="Lecture08.pdf">Prefix sum pattern</a> </td> <td> </td> </tr>
<tr> <td> 4 / 17 </td> <td> <a href="Lecture09.pdf">Histogram pattern</a> </td> <td> </td> </tr>
<tr> <td> 4 / 19 </td> <td> <a href="Lecture10.pdf">Sparse matrix pattern</a> </td> <td> TiledMatrixMultiplication due  </td> </tr>
<tr> <td> 4 / 24 </td> <td> <a href="Lecture11.pdf">Merge sort pattern</a> </td> <td> <a href="assignment2">Assignment 2</a> </td>  </tr>
<tr> <td> 4 / 26 </td> <td> <a href="Lecture12.pdf">Graph search pattern</a> </td> <td> </td> </tr>
<tr> <td> 5 / 01 </td> <td> <a href="Lecture13.pdf">Advanced host / device interface</a> <br/> <a href="Lecture14.pdf">Streams, events, and concurrency</a> </td> <td> </td> </tr>
<tr> <td> 5 / 03 </td> <td> <a href="Lecture15.pdf">Dynamic parallelism / recursion</a> </td> <td> </td> </tr>
<tr> <td> 5 / 08 </td> <td> <a href="Lecture16.pdf">Floating point considerations</a> <br />  <a href="Lecture17.pdf">Intrinsic Functions</a> </td> <td> Assignment 2 due <br /> <a href="finalProject"/>Final project</a> </td> </tr>
<tr> <td> 5 / 10 </td> <td> <a href="Lecture18.pdf">In-warp shuffles</a> </td> <td> </td> </tr>
<tr> <td> 5 / 15 </td> <td> <a href="Lecture19.pdf">Multi-GPU programming</a> </td> <td> Final project proposal due </td> </tr>
<tr> <td> 5 / 17 </td> <td> cuDNN <a href="http://dlsys.cs.washington.edu/schedule">CSE 599g</a> <br /> <br /> 5/18 1-2pm @CSE305 </td> <td> </td> </tr>
<tr> <td> 5 / 22 </td> <td> <a href="Lecture20.pdf">OpenCL / OpenACC</a> </td> <td> </td> </tr>
<tr> <td> 5 / 24 </td> <td> Deep Learning and Tensor Core </td> <td> </td> </tr>
<tr> <td> 5 / 29 </td> <td> Graph Processing with GPU </td> <td> </td> </tr>
<tr> <td> 5 / 31 </td> <td> Ray Tracing </td> <td> </td> </tr>
<tr> <td> 6 / 01 </td> <td> Misc  </td> <td> Final project due </td> </tr>
</table>

</div>

</body>
</html>
